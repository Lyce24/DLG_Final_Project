{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UBE2Q2P2_rnaseq</th>\n",
       "      <th>SSX9_rnaseq</th>\n",
       "      <th>CXORF67_rnaseq</th>\n",
       "      <th>EFCAB8_rnaseq</th>\n",
       "      <th>SDR16C6P_rnaseq</th>\n",
       "      <th>EFCAB12_rnaseq</th>\n",
       "      <th>A1BG_rnaseq</th>\n",
       "      <th>A1CF_rnaseq</th>\n",
       "      <th>RBFOX1_rnaseq</th>\n",
       "      <th>GGACT_rnaseq</th>\n",
       "      <th>...</th>\n",
       "      <th>ZWINT_rnaseq</th>\n",
       "      <th>ZXDA_rnaseq</th>\n",
       "      <th>ZXDB_rnaseq</th>\n",
       "      <th>ZXDC_rnaseq</th>\n",
       "      <th>ZYG11A_rnaseq</th>\n",
       "      <th>ZYG11B_rnaseq</th>\n",
       "      <th>ZYX_rnaseq</th>\n",
       "      <th>ZZEF1_rnaseq</th>\n",
       "      <th>ZZZ3_rnaseq</th>\n",
       "      <th>TPTEP1_rnaseq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.7786</td>\n",
       "      <td>0.3153</td>\n",
       "      <td>6.6560</td>\n",
       "      <td>2.0252</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.4304</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>-0.0589</td>\n",
       "      <td>-0.2273</td>\n",
       "      <td>-0.6056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>-0.1816</td>\n",
       "      <td>-0.4114</td>\n",
       "      <td>1.0797</td>\n",
       "      <td>1.0743</td>\n",
       "      <td>-1.0477</td>\n",
       "      <td>0.9689</td>\n",
       "      <td>-0.3256</td>\n",
       "      <td>-1.1244</td>\n",
       "      <td>2.4038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.7786</td>\n",
       "      <td>0.3153</td>\n",
       "      <td>6.6560</td>\n",
       "      <td>2.0252</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.4304</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>-0.0589</td>\n",
       "      <td>-0.2273</td>\n",
       "      <td>-0.6056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>-0.1816</td>\n",
       "      <td>-0.4114</td>\n",
       "      <td>1.0797</td>\n",
       "      <td>1.0743</td>\n",
       "      <td>-1.0477</td>\n",
       "      <td>0.9689</td>\n",
       "      <td>-0.3256</td>\n",
       "      <td>-1.1244</td>\n",
       "      <td>2.4038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2949</td>\n",
       "      <td>-0.0752</td>\n",
       "      <td>-0.1184</td>\n",
       "      <td>0.7840</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.5511</td>\n",
       "      <td>1.1618</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>-0.2273</td>\n",
       "      <td>1.2238</td>\n",
       "      <td>...</td>\n",
       "      <td>3.2911</td>\n",
       "      <td>-1.1222</td>\n",
       "      <td>-0.1302</td>\n",
       "      <td>-1.4793</td>\n",
       "      <td>2.5267</td>\n",
       "      <td>-1.3026</td>\n",
       "      <td>0.9433</td>\n",
       "      <td>-1.1210</td>\n",
       "      <td>-0.9310</td>\n",
       "      <td>-0.6472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2949</td>\n",
       "      <td>-0.0752</td>\n",
       "      <td>-0.1184</td>\n",
       "      <td>0.7840</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.5511</td>\n",
       "      <td>1.1618</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>-0.2273</td>\n",
       "      <td>1.2238</td>\n",
       "      <td>...</td>\n",
       "      <td>3.2911</td>\n",
       "      <td>-1.1222</td>\n",
       "      <td>-0.1302</td>\n",
       "      <td>-1.4793</td>\n",
       "      <td>2.5267</td>\n",
       "      <td>-1.3026</td>\n",
       "      <td>0.9433</td>\n",
       "      <td>-1.1210</td>\n",
       "      <td>-0.9310</td>\n",
       "      <td>-0.6472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6318</td>\n",
       "      <td>-0.0752</td>\n",
       "      <td>-0.1184</td>\n",
       "      <td>0.4122</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.0254</td>\n",
       "      <td>-0.0206</td>\n",
       "      <td>-0.0589</td>\n",
       "      <td>-0.2273</td>\n",
       "      <td>-0.7747</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2431</td>\n",
       "      <td>-0.3657</td>\n",
       "      <td>-0.4472</td>\n",
       "      <td>-1.0557</td>\n",
       "      <td>0.8232</td>\n",
       "      <td>-1.0342</td>\n",
       "      <td>1.0729</td>\n",
       "      <td>-1.4634</td>\n",
       "      <td>-0.5710</td>\n",
       "      <td>-0.5402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>-0.7923</td>\n",
       "      <td>-0.0752</td>\n",
       "      <td>-0.0801</td>\n",
       "      <td>1.0912</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.4945</td>\n",
       "      <td>1.4065</td>\n",
       "      <td>-0.0589</td>\n",
       "      <td>-0.2273</td>\n",
       "      <td>-0.7904</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.1686</td>\n",
       "      <td>-1.5424</td>\n",
       "      <td>-1.0868</td>\n",
       "      <td>-1.4608</td>\n",
       "      <td>-0.0141</td>\n",
       "      <td>-2.0773</td>\n",
       "      <td>3.9959</td>\n",
       "      <td>-1.4221</td>\n",
       "      <td>-1.0560</td>\n",
       "      <td>1.7134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>2.5181</td>\n",
       "      <td>-0.0752</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.1302</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.5155</td>\n",
       "      <td>0.1434</td>\n",
       "      <td>-0.0589</td>\n",
       "      <td>-0.1814</td>\n",
       "      <td>0.6160</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.6444</td>\n",
       "      <td>0.2435</td>\n",
       "      <td>0.2311</td>\n",
       "      <td>0.7384</td>\n",
       "      <td>-0.8560</td>\n",
       "      <td>-0.7456</td>\n",
       "      <td>0.7535</td>\n",
       "      <td>0.9765</td>\n",
       "      <td>-0.6290</td>\n",
       "      <td>-0.4313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>3.5801</td>\n",
       "      <td>-0.0752</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>0.0402</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.0863</td>\n",
       "      <td>0.3059</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>-0.0621</td>\n",
       "      <td>-0.4222</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1942</td>\n",
       "      <td>-0.6109</td>\n",
       "      <td>-0.7641</td>\n",
       "      <td>1.2241</td>\n",
       "      <td>0.7029</td>\n",
       "      <td>-0.5363</td>\n",
       "      <td>0.9538</td>\n",
       "      <td>-0.0743</td>\n",
       "      <td>-0.0954</td>\n",
       "      <td>0.0371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>-0.0576</td>\n",
       "      <td>-0.0752</td>\n",
       "      <td>-0.1184</td>\n",
       "      <td>-0.4279</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.4510</td>\n",
       "      <td>1.2449</td>\n",
       "      <td>-0.0589</td>\n",
       "      <td>-0.1577</td>\n",
       "      <td>-0.3944</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0210</td>\n",
       "      <td>-1.2416</td>\n",
       "      <td>-1.0705</td>\n",
       "      <td>-1.3571</td>\n",
       "      <td>-0.5215</td>\n",
       "      <td>-1.3964</td>\n",
       "      <td>1.6214</td>\n",
       "      <td>-1.5199</td>\n",
       "      <td>-0.4771</td>\n",
       "      <td>0.0497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>3.1259</td>\n",
       "      <td>-0.0752</td>\n",
       "      <td>-0.1020</td>\n",
       "      <td>0.8205</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.2712</td>\n",
       "      <td>-0.0589</td>\n",
       "      <td>-0.2273</td>\n",
       "      <td>-1.5300</td>\n",
       "      <td>...</td>\n",
       "      <td>3.1100</td>\n",
       "      <td>-1.1572</td>\n",
       "      <td>-0.6053</td>\n",
       "      <td>-0.6814</td>\n",
       "      <td>0.4323</td>\n",
       "      <td>-1.1552</td>\n",
       "      <td>-0.2025</td>\n",
       "      <td>-1.9221</td>\n",
       "      <td>-1.0202</td>\n",
       "      <td>-0.6968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1023 rows Ã— 18428 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      UBE2Q2P2_rnaseq  SSX9_rnaseq  CXORF67_rnaseq  EFCAB8_rnaseq  \\\n",
       "0              1.7786       0.3153          6.6560         2.0252   \n",
       "1              1.7786       0.3153          6.6560         2.0252   \n",
       "2              0.2949      -0.0752         -0.1184         0.7840   \n",
       "3              0.2949      -0.0752         -0.1184         0.7840   \n",
       "4              0.6318      -0.0752         -0.1184         0.4122   \n",
       "...               ...          ...             ...            ...   \n",
       "1018          -0.7923      -0.0752         -0.0801         1.0912   \n",
       "1019           2.5181      -0.0752          0.0112         0.1302   \n",
       "1020           3.5801      -0.0752          0.7033         0.0402   \n",
       "1021          -0.0576      -0.0752         -0.1184        -0.4279   \n",
       "1022           3.1259      -0.0752         -0.1020         0.8205   \n",
       "\n",
       "      SDR16C6P_rnaseq  EFCAB12_rnaseq  A1BG_rnaseq  A1CF_rnaseq  \\\n",
       "0              -0.116         -0.4304       0.2155      -0.0589   \n",
       "1              -0.116         -0.4304       0.2155      -0.0589   \n",
       "2              -0.116         -0.5511       1.1618       0.1349   \n",
       "3              -0.116         -0.5511       1.1618       0.1349   \n",
       "4              -0.116         -0.0254      -0.0206      -0.0589   \n",
       "...               ...             ...          ...          ...   \n",
       "1018           -0.116         -0.4945       1.4065      -0.0589   \n",
       "1019           -0.116         -0.5155       0.1434      -0.0589   \n",
       "1020           -0.116         -0.0863       0.3059       0.4459   \n",
       "1021           -0.116         -0.4510       1.2449      -0.0589   \n",
       "1022           -0.116          0.4750       0.2712      -0.0589   \n",
       "\n",
       "      RBFOX1_rnaseq  GGACT_rnaseq  ...  ZWINT_rnaseq  ZXDA_rnaseq  \\\n",
       "0           -0.2273       -0.6056  ...        0.3196      -0.1816   \n",
       "1           -0.2273       -0.6056  ...        0.3196      -0.1816   \n",
       "2           -0.2273        1.2238  ...        3.2911      -1.1222   \n",
       "3           -0.2273        1.2238  ...        3.2911      -1.1222   \n",
       "4           -0.2273       -0.7747  ...       -0.2431      -0.3657   \n",
       "...             ...           ...  ...           ...          ...   \n",
       "1018        -0.2273       -0.7904  ...       -1.1686      -1.5424   \n",
       "1019        -0.1814        0.6160  ...       -0.6444       0.2435   \n",
       "1020        -0.0621       -0.4222  ...       -0.1942      -0.6109   \n",
       "1021        -0.1577       -0.3944  ...       -1.0210      -1.2416   \n",
       "1022        -0.2273       -1.5300  ...        3.1100      -1.1572   \n",
       "\n",
       "      ZXDB_rnaseq  ZXDC_rnaseq  ZYG11A_rnaseq  ZYG11B_rnaseq  ZYX_rnaseq  \\\n",
       "0         -0.4114       1.0797         1.0743        -1.0477      0.9689   \n",
       "1         -0.4114       1.0797         1.0743        -1.0477      0.9689   \n",
       "2         -0.1302      -1.4793         2.5267        -1.3026      0.9433   \n",
       "3         -0.1302      -1.4793         2.5267        -1.3026      0.9433   \n",
       "4         -0.4472      -1.0557         0.8232        -1.0342      1.0729   \n",
       "...           ...          ...            ...            ...         ...   \n",
       "1018      -1.0868      -1.4608        -0.0141        -2.0773      3.9959   \n",
       "1019       0.2311       0.7384        -0.8560        -0.7456      0.7535   \n",
       "1020      -0.7641       1.2241         0.7029        -0.5363      0.9538   \n",
       "1021      -1.0705      -1.3571        -0.5215        -1.3964      1.6214   \n",
       "1022      -0.6053      -0.6814         0.4323        -1.1552     -0.2025   \n",
       "\n",
       "      ZZEF1_rnaseq  ZZZ3_rnaseq  TPTEP1_rnaseq  \n",
       "0          -0.3256      -1.1244         2.4038  \n",
       "1          -0.3256      -1.1244         2.4038  \n",
       "2          -1.1210      -0.9310        -0.6472  \n",
       "3          -1.1210      -0.9310        -0.6472  \n",
       "4          -1.4634      -0.5710        -0.5402  \n",
       "...            ...          ...            ...  \n",
       "1018       -1.4221      -1.0560         1.7134  \n",
       "1019        0.9765      -0.6290        -0.4313  \n",
       "1020       -0.0743      -0.0954         0.0371  \n",
       "1021       -1.5199      -0.4771         0.0497  \n",
       "1022       -1.9221      -1.0202        -0.6968  \n",
       "\n",
       "[1023 rows x 18428 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "# import the data\n",
    "df = pandas.read_csv('../data/tcga_brca_all_clean.csv')\n",
    "df = df.iloc[:, 9:]\n",
    "\n",
    "df_cnv = df.filter(regex='_cnv', axis=1)\n",
    "df_rnaseq = df.filter(regex='_rnaseq', axis=1)\n",
    "df_mut = df.filter(regex='_mut', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2523, 1023)\n"
     ]
    }
   ],
   "source": [
    "# Transpose: rows=genes, cols=samples\n",
    "gene_features = df_cnv.T\n",
    "genes = gene_features.index.tolist()\n",
    "\n",
    "print(gene_features.shape)  # Should be (2523, 1023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges: 426962\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Compute cosine similarity between genes\n",
    "sim_matrix = cosine_similarity(gene_features)\n",
    "\n",
    "# Threshold to form edges\n",
    "threshold = 0.9  # adjust based on sparsity you desire\n",
    "edge_index = np.argwhere(sim_matrix > threshold)\n",
    "\n",
    "# Remove self-loops and duplicates\n",
    "edge_index = edge_index[edge_index[:,0] != edge_index[:,1]]\n",
    "edge_index = edge_index.T\n",
    "\n",
    "print(f\"Number of edges: {edge_index.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2523, 1023], edge_index=[2, 426962])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Node features: CNV profiles (2523 genes x 1023 samples)\n",
    "x = torch.tensor(gene_features.values, dtype=torch.float)\n",
    "\n",
    "# Edge index (2, num_edges)\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, BatchNorm\n",
    "\n",
    "class ComplexCNVGAT(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=256, embed_dim=64, heads=4, dropout=0.3):\n",
    "        super(ComplexCNVGAT, self).__init__()\n",
    "        \n",
    "        self.gat1 = GATConv(input_dim, hidden_dim, heads=heads, dropout=dropout)\n",
    "        self.norm1 = BatchNorm(hidden_dim * heads)\n",
    "        \n",
    "        self.gat2 = GATConv(hidden_dim * heads, hidden_dim, heads=heads, dropout=dropout)\n",
    "        self.norm2 = BatchNorm(hidden_dim * heads)\n",
    "\n",
    "        # Final embedding layer (single head)\n",
    "        self.gat3 = GATConv(hidden_dim * heads, embed_dim, heads=1, concat=True, dropout=dropout)\n",
    "        self.norm3 = BatchNorm(embed_dim)\n",
    "        \n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # Layer 1\n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = self.norm1(x)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        \n",
    "        # Layer 2\n",
    "        x = self.gat2(x, edge_index)\n",
    "        x = self.norm2(x)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        \n",
    "        # Final Embedding Layer\n",
    "        x = self.gat3(x, edge_index)\n",
    "        x = self.norm3(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 950.5826\n",
      "Epoch 10, Loss: 460.2672\n",
      "Epoch 20, Loss: 434.7167\n",
      "Epoch 30, Loss: 383.9095\n",
      "Epoch 40, Loss: 339.6143\n",
      "Epoch 50, Loss: 313.7188\n",
      "Epoch 60, Loss: 288.6734\n",
      "Epoch 70, Loss: 269.1189\n",
      "Epoch 80, Loss: 247.0448\n",
      "Epoch 90, Loss: 238.1196\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "input_dim = 1023  # Number of patients/samples\n",
    "hidden_dim = 256\n",
    "embed_dim = 64\n",
    "heads = 4\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = ComplexCNVGAT(input_dim, hidden_dim, embed_dim, heads=heads).to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "model.train()\n",
    "\n",
    "data = data.to(device)\n",
    "model.train()\n",
    "\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    embeddings = model(data.x, data.edge_index)\n",
    "\n",
    "    # Unsupervised scenario: Graph reconstruction or embedding smoothness\n",
    "    # For demonstration, using smoothness loss (nodes close in graph should have similar embeddings)\n",
    "    loss = torch.norm(embeddings[data.edge_index[0]] - embeddings[data.edge_index[1]], p=2).mean()\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
