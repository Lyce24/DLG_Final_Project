# Surv-MÂ²AC: Masked Multimodal Autoencoders with Contrastive Learning for Cancer Survival Prediction

**Authors:** Yancheng Liu, David Ning, Yang Xiang  
**Institution:** Department of Computer Science, Brown University  
**Corresponding Author:** yancheng_liu@brown.edu  

## ğŸ§¬ Overview

**Surv-MÂ²AC** is a lightweight and interpretable model for pan-cancer survival analysis that combines:
- **Modality-specific masked autoencoders**
- **Bidirectional Feature-wise Linear Modulation (Bi-FiLM)** for cross-modal fusion
- **Contrastive learning** for robust patient representation

This framework is optimized for sparse real-world data, using only binary gene mutation profiles and limited clinical features. Despite minimal inputs, Surv-MÂ²AC achieves competitive performance with fewer parameters and better generalizability across cancer types.

## ğŸ” Key Features

- ğŸ§  **Modality-Specific Encoders:** Deep residual blocks for gene mutation profiles and lightweight blocks for clinical data.
- ğŸ”„ **Bi-FiLM Fusion:** Cross-modal interaction through mutual feature-wise conditioning.
- ğŸ§© **Masked Reconstruction:** Robust autoencoding under partial feature dropout.
- ğŸ¯ **Contrastive Learning:** SimCLR-style loss ensures representation stability across corruptions.
- ğŸ“ˆ **Downstream Performance:** Achieves an average C-index of **0.744** on MSK-IMPACT data.
- ğŸ§  **Interpretability:** Integrated Gradients reveal biologically meaningful feature attributions.

## ğŸ“‚ Dataset

Surv-MÂ²AC is evaluated on a pan-cancer dataset from **MSK-IMPACT**, comprising:
- 22,284 patients across 5 major cancer types
- 1,165 binarized gene mutation subtypes
- 16 curated clinical features

Please note: Due to privacy concerns, the dataset is not included in this repository. Contact the authors for access or guidance on data preprocessing.

## ğŸ—ï¸ Architecture

<p align="center">
  <img src="./figures/mac.png" alt="Surv-MÂ²AC Architecture" width="600"/>
</p>

- **Encoders:** Separate MLP-based encoders with residual and SE blocks.
- **Fusion Layer:** Bi-FiLM block conditions each modality on the other.
- **Decoders:** Two-layer MLPs reconstruct masked inputs.
- **Projection Head:** Outputs contrastive embeddings \( h \).

## âš™ï¸ Training Objective

Combined loss:
- **Masked Reconstruction Loss** for gene and clinical modalities
- **Contrastive Loss (InfoNCE)** between two masked views of each sample

Total loss:
```
L_total = L_recon + Î² * L_contrastive
```

## ğŸ“Š Results

| Model Variant                | Avg. C-Index |
|-----------------------------|--------------|
| DeepSurv Baseline           | 0.706        |
| Vanilla Autoencoder         | 0.704        |
| Surv-MÂ²AC (no fusion/losses)| 0.724        |
| **Full Surv-MÂ²AC**          | **0.744**    |

- Kaplanâ€“Meier curves show better risk group stratification.
- UMAP visualizations confirm biologically coherent embeddings.

## ğŸ“ Repository Structure

```
.
â”œâ”€â”€ data_processing/          # Preprocessed MSK dataset
â”œâ”€â”€ env/                      # Environment setup
â”œâ”€â”€ figures/                  # Model architecture and results
â”œâ”€â”€ models/                   # Main Surv-MÂ²AC model
â”œâ”€â”€ results/                  # Model evaluation results
â”œâ”€â”€ utils/                    # Training and evaluation scripts
â”œâ”€â”€ experiments.py            # Experiment configuration for Surv-MÂ²AC
â”œâ”€â”€ mlp_baseline.ipynb        # MLP baseline model (DeepSurv)
â”œâ”€â”€ README.md
â”œâ”€â”€ Surv-MAC.ipynb            # Surv-MÂ²AC model notebook
â””â”€â”€ Surv-MAC.pdf              # Surv-MÂ²AC model paper
```

## ğŸ“Œ Requirements

- Python â‰¥ 3.8
- PyTorch â‰¥ 1.10
- NumPy, pandas, scikit-learn
- Matplotlib, UMAP
- Lifelines
- Captum

Install dependencies:

```bash
pip install -r ./env/requirements.txt
```

## ğŸ“¬ Contact

For questions or collaboration inquiries, please contact:  
**Yancheng Liu** â€“ yancheng_liu@brown.edu
